---
title: "Forecasting Heart Disease Risks: Gradient Boosting Machine (GBM)"
output:
  flexdashboard::flex_dashboard:
    logo: "../image/logo.gif"
    theme:
      version: 4
      bootswatch: cosmo
      base_font:
        google: Montserrat
      code_font:
        google: Inconsolata
    orientation: columns
    vertical_layout: fill
---

<style>
body {
  font-size: 16px;
}
h4 {
  font-size: 24px;
}
h1, h2, h3 {
  font-size: 28px;
}
</style>


```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(flexdashboard)
#Install thematic and un-comment for themed static plots (i.e., ggplot2)
#thematic::thematic_rmd(font = "auto")

# Install necessary packages if they are not already installed.
if (!requireNamespace("RCurl", quietly = TRUE)) {
  install.packages("RCurl")
}
if (!requireNamespace("tidyverse", quietly = TRUE)) {
  install.packages("tidyverse")
}
if (!requireNamespace("patchwork", quietly = TRUE)) {
  install.packages("patchwork")
}
if (!requireNamespace("corrplot", quietly = TRUE)) {
  install.packages("corrplot")
}

# Load the required libraries
library(RCurl)
library(tidyverse)
library(patchwork)
library(corrplot)
library(GGally)
```

Column {data-width=600 .tabset}
-----------------------------------------------------------------------

### BUSINESS UNDERSTANDING

```{r}

```



### DATA UNDERSTANDING

```{r}

```



### DATA PREPARATION

```{r}

```



### MODELING

```{r}

```



### EVALUATION

```{r}

```



### DEPLOYMENT

```{r}

```




Column {data-width=250 .tabset}
-----------------------------------------------------------------------

### PROBLEM STATEMENT

```{r}

```

####

```{r echo=FALSE, out.width = "70%", fig.align = "center"}
knitr::include_graphics("../image/heart.png")
```

### CONCLUSION

```{r}

```

Column {data-width=150 .tabset}
-----------------------------------------------------------------------

### Gradient Boosting Machine

**Overview:**

- An ensemble technique that builds trees sequentially, each one learning from the errors of the previous.
- Focuses on reducing bias and improving predictive accuracy.

**Advantages:**

- High predictive performance.
- Can handle various types of predictor variables.
- Offers flexibility through different loss functions.

**Disadvantages:**

- Computationally intensive and slower to train.
- Sensitive to overfitting if not tuned carefully.
- Many hyperparameters to tune (can be complex to optimize).

